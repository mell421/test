---
title: "ugo"
output:
  html_document:
    df_print: paged
    toc: true
---

```{r setup, include = FALSE}
suppressWarnings(source("./R/sources.R"))
library("tm")
library(textstem)
#install.koRpus.lang("fr")
library("koRpus.lang.fr")
require(koRpus)
delayW <- 5
myRemoveListU <- c("les", "la")
myToSpaceListU <- c("@","\\|","'<'","\\'","/","\'")
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
removeAccentE <- content_transformer(function (x , pattern ) gsub(pattern, "e", x))
removeAccentA <- content_transformer(function (x , pattern ) gsub(pattern, "a", x))
removeC <- content_transformer(function (x , pattern ) gsub(pattern, "c", x))
removeSpace <- content_transformer(function (x , pattern ) gsub(pattern, "", x))

wcLemme <- function(text){
  TextDoc <- Corpus(VectorSource(text))
  TextDoc <- tm_map(TextDoc, toSpace, myToSpaceListU)
  TextDoc <- tm_map(TextDoc, content_transformer(tolower))
  TextDoc <- tm_map(TextDoc, removeWords, myRemoveListU)
  TextDoc <- tm_map(TextDoc, removeNumbers)
  TextDoc <- tm_map(TextDoc, removePunctuation)
  TextDoc <- tm_map(TextDoc, stripWhitespace)
  TextDoc <- tm_map(TextDoc, removeNumbers)
  TextDoc <- tm_map(TextDoc, removeWords, stopwords("french"))
  TextDoc <- tm_map(TextDoc, lemmatize_strings)
  TextDoc <- tm_map(TextDoc, lemmatisation)


  # Build a term-document matrix
  TextDoc_dtm <- TermDocumentMatrix(TextDoc)
  dtm_m <- as.matrix(TextDoc_dtm)
  # Sort by decreasing value of frequency
  dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
  dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)

  return(dtm_d)
}



lemmatisation <- function(TextDoc){
  ##my.df est un objet Corpus issu de du chargement du corpus avec tm
  #print(TextDoc)
  dictionnaire <- data.frame()
  for(i in 1 : length(TextDoc)){
    lemma <- treetag(TextDoc[[i]][[1]], treetagger = "manual", format = "obj", TT.tknz = FALSE, 
                     lang = "fr", TT.options = list(path = "treetagger", preset = "fr-utf8"))
    dictionnaire <- rbind(dictionnaire, lemma@TT.res )
  }
  return(unique(dictionnaire))
}
```

------------------------------------------------------------------------

```{r a1 , echo=FALSE}
# Give the input file name to the function.
CommPos <- read.csv(file = "dfCommPos.csv")
dfCommPos <- data.frame(CommPos)
dfCommPos
#print(dfCommPos)

CommNeu <- read.csv(file = "dfCommNeu.csv")
dfCommNeu <- data.frame(CommNeu)
dfCommNeu
#print(dfCommNeu)

CommNeg <- read.csv(file = "dfCommNeg.csv")
dfCommNeg <- data.frame(CommNeg)
dfCommNeg

CommAll <- read.csv(file = "ugoComments.csv")
dfCommAll <- data.frame(CommAll)
dfCommAll

SsCommAll <- read.csv(file = "ugoSsComments.csv")
dfSsCommAll <- data.frame(SsCommAll)
dfSsCommAll

All <- read.csv(file = "ugo.csv")
dfAll <- data.frame(All)
dfAll
```

```{r a2 , echo=FALSE}
library(sentimentr)

## Not run: 
sentiment_attributes(presidential_debates_2012$dialogue)

## End(Not run)

require(graphics)

### Example 1: Violent crime rates by US state

hc <- hclust(dist(USArrests), "ave")
plot(hc)
plot(hc, hang = -1)

## Do the same with centroid clustering and *squared* Euclidean distance,
## cut the tree into ten clusters and reconstruct the upper part of the
## tree from the cluster centers.
hc <- hclust(dist(USArrests)^2, "cen")
memb <- cutree(hc, k = 10)
cent <- NULL
for(k in 1:10){
  cent <- rbind(cent, colMeans(USArrests[memb == k, , drop = FALSE]))
}
hc1 <- hclust(dist(cent)^2, method = "cen", members = table(memb))
opar <- par(mfrow = c(1, 2))
plot(hc,  labels = FALSE, hang = -1, main = "Original Tree")
plot(hc1, labels = FALSE, hang = -1, main = "Re-start from 10 clusters")
par(opar)

### Example 2: Straight-line distances among 10 US cities
##  Compare the results of algorithms "ward.D" and "ward.D2"

mds2 <- -cmdscale(UScitiesD)
plot(mds2, type="n", axes=FALSE, ann=FALSE)
text(mds2, labels=rownames(mds2), xpd = NA)

hcity.D  <- hclust(UScitiesD, "ward.D") # "wrong"
hcity.D2 <- hclust(UScitiesD, "ward.D2")
opar <- par(mfrow = c(1, 2))
plot(hcity.D,  hang=-1)
plot(hcity.D2, hang=-1)
par(opar)



```

```{r all1, echo=FALSE}
install.packages("VennDiagram")
library("VennDiagram")
draw.triple.venn(area1 = 65,area2 = 75,area3 = 85,n12 = 35,n23 = 15,n13 = 25,n123 = 5,category = c("Qualité", "Sécurité", "Environnement"))
```

### all

```{r all1, echo=FALSE}
text <- dfCommAll$tradFr
print("origine")
tm <- function(text){
  dtm_d <- wc(text)
  # Display the top 20 most frequent words
  head(dtm_d, 30)

  # Plot the most frequent words
  barplotSimple(dtm_d[1:20,]$freq,dtm_d[1:20,]$word,"Top 20 all")
  
  #generate word cloud
  wcSimple(dtm_d$word,dtm_d$freq)
  wcDouble(dtm_d,"circle","UgoAll1.png",delayW)

}

suppressWarnings(tm(text))
print("après stemmer")

tm <- function(text){
  dtm_d <- wcLemme(text)
  # Display the top 20 most frequent words
  head(dtm_d, 30)

  # Plot the most frequent words
  barplotSimple(dtm_d[1:20,]$freq,dtm_d[1:20,]$word,"Top 20 all")
  
  #generate word cloud
  wcSimple(dtm_d$word,dtm_d$freq)
  wcDouble(dtm_d,"circle","UgoAll2.png",delayW)

}

suppressWarnings(tm(text))
```

### pos

```{r pos1, echo=FALSE}
text <- data.frame(dfCommPos$tradFr)
print("origine")

tm <- function(text){
  dtm_d <- wc(text)
  # Display the top 20 most frequent words
  head(dtm_d, 30)

  # Plot the most frequent words
  barplotSimple(dtm_d[1:20,]$freq,dtm_d[1:20,]$word,"Top 20 pos")
  
  #generate word cloud
  wcSimple(dtm_d$word,dtm_d$freq)
  wcDouble(dtm_d,"circle","UgoPos1.png",delayW)

}

suppressWarnings(tm(text))
print("après stemmer")

tm <- function(text){
  dtm_d <- wcLemme(text)
  # Display the top 20 most frequent words
  head(dtm_d, 30)

  # Plot the most frequent words
  barplotSimple(dtm_d[1:20,]$freq,dtm_d[1:20,]$word,"Top 20 pos")
  
  #generate word cloud
  wcSimple(dtm_d$word,dtm_d$freq)
  wcDouble(dtm_d,"circle","UgoPos2.png",delayW)

}

suppressWarnings(tm(text))
```

### neu

```{r neu1, echo=FALSE}
text <- data.frame(dfCommNeu$tradFr)
print("origine")

tm <- function(text){
  dtm_d <- wc(text)
  # Display the top 20 most frequent words
  head(dtm_d, 30)

  # Plot the most frequent words
  barplotSimple(dtm_d[1:20,]$freq,dtm_d[1:20,]$word,"Top 20 neu")
  
  #generate word cloud
  wcSimple(dtm_d$word,dtm_d$freq)
  wcDouble(dtm_d,"circle","UgoNeu1.png",delayW)

}

suppressWarnings(tm(text))
print("après stemmer")

tm <- function(text){
  dtm_d <- wcLemme(text)
  # Display the top 20 most frequent words
  head(dtm_d, 30)

  # Plot the most frequent words
  barplotSimple(dtm_d[1:20,]$freq,dtm_d[1:20,]$word,"Top 20 neu")
  
  #generate word cloud
  wcSimple(dtm_d$word,dtm_d$freq)
  wcDouble(dtm_d,"circle","UgoNeu2.png",delayW)

}

suppressWarnings(tm(text))
```

### neg

```{r neg1, echo=FALSE}
text <- data.frame(dfCommNeg$tradFr)
print("origine")

tm <- function(text){
  dtm_d <- wc(text)
  # Display the top 20 most frequent words
  head(dtm_d, 30)

  # Plot the most frequent words
  barplotSimple(dtm_d[1:20,]$freq,dtm_d[1:20,]$word,"Top 20 neg")
  
  #generate word cloud
  wcSimple(dtm_d$word,dtm_d$freq)
  wcDouble(dtm_d,"circle","UgoNeg1.png",delayW)

}


suppressWarnings(tm(text))
print("après stemmer")
tm <- function(text){
  dtm_d <- wcLemme(text)
  # Display the top 20 most frequent words
  head(dtm_d, 30)

  # Plot the most frequent words
  barplotSimple(dtm_d[1:20,]$freq,dtm_d[1:20,]$word,"Top 20 neg")
  
  #generate word cloud
  wcSimple(dtm_d$word,dtm_d$freq)
  wcDouble(dtm_d,"circle","UgoNeg2.png",delayW)

}

suppressWarnings(tm(text))
```

### AUTRES GRAPHIQUES
#### barplot comments
```{r g1 , echo=FALSE}
barplot(table(dfCommAll$ratingUser),
        las = 2,
        col =brewer.pal(8, "Dark2"), 
        main ="rating user",
        ylab = "nb commentaire")
        
box()

barplot(table(dfCommAll$ratingText),
        las = 2,
        col =brewer.pal(8, "Dark2"), 
        main ="rating text",
        ylab = "nb commentaire")
        
box()

pie(table(dfCommAll$ratingUser),label=paste(names(table(dfCommAll$ratingUser)),table(dfCommAll$ratingUser),sep="-"))
title("distribution des notes utilisateur avec comm")
box()

pie(table(dfSsCommAll$ratingUser),label=paste(names(table(dfSsCommAll$ratingUser)),table(dfSsCommAll$ratingUser),sep="-"))
title("distribution des notes utilisateur sans comm")
box()

pie(table(dfAll$ratingUser),label=paste(names(table(dfAll$ratingUser)),table(dfAll$ratingUser),sep="-"))
title("distribution des notes utilisateur")
box()

hist(dfCommAll$ratingUser)
hist(dfCommAll$scoreEngCom)
hist(dfCommAll$scoreEngNeg)
hist(dfCommAll$scoreEngNeu)
hist(dfCommAll$scoreEngPos)
hist(dfCommAll$scoreTextFrGT)
hist(dfCommAll$scoreText)

plot(dfCommAll$scoreTextFrGT~factor(dfCommAll$ratingUser),xlab="note utilisateur",ylab="Score francais",col="#FCD203")

plot(dfCommAll$scoreEngCom~factor(dfCommAll$ratingUser),xlab="note utilisateur",ylab="Score anglais",col="#FCD203")
```
